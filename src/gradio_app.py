import os

import numpy as np
import pandas as pd
import gradio as gr

from modules.bbox import run_detection
from modules.ocr import run_ocr
    
MODEL_PATHS = [
    'v2023.12.07_s_yv11'
]

INIT_STATE = {
    "input_img": None,
    "detections": None,
    "detect_img": None,
    "ocr_df": pd.DataFrame(columns=["BOX ID","COORDINATES","DETECTED TEXT"]),
#     "image_copy": None,
#     "auto_mask": np.array([]),
#     "inpaint": None,
}

with gr.Blocks(theme=gr.themes.Soft(), title="MangaFlow AI Image Translator") as demo:
    gr.Markdown(
        """
        # ğŸ“š MangaFlow Text Detector
        Upload a manga image and select a YOLO model to detect text regions.
        """
    )

    # â‡ï¸ íƒ­ ê°„ ë°ì´í„° ê³µìœ ë¥¼ ìœ„í•œ ìƒíƒœ ë³€ìˆ˜
    st = gr.State(value=INIT_STATE)

    # ocr_data_state = gr.State(value=(None, None))
    # ocr_df_state = gr.State(value=pd.DataFrame(columns=["BOX ID", "COORDINATES", "DETECTED TEXT"]))
    # image_copy_state = gr.State(value=None)
    # auto_mask_state = gr.State(value=np.array([])) 
    # inpainting_result_state = gr.State(value=None)

    with gr.Tabs():
        # --- íƒ­ 1: í…ìŠ¤íŠ¸ ê°ì§€ ---
        with gr.TabItem("1. Detect Text", elem_id="tab_detect"):
            detect_button = gr.Button("Detect Textboxes from Image", variant="primary")
                                 
            with gr.Row():
                with gr.Column(scale=1):
                    # ì›ë³¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ
                    img_input = gr.Image(type="numpy", label="ğŸ“¤ Upload Manga Image")
                                    
                with gr.Column(scale=1):
                    detect_output = gr.Image(label="Detected Text Regions", interactive=False)
            
            model_dropdown = gr.Dropdown(
                MODEL_PATHS,
                value=MODEL_PATHS[0],
                label="Select YOLO Model"
            )
            with gr.Row():
                with gr.Column(scale=1):
                    iou_slider = gr.Slider(
                        minimum=0.0,
                        maximum=1.0,
                        step=0.1,
                        value=0.7,
                        label="IOU Threshold"
                    )
                with gr.Column(scale=1):
                    conf_slider = gr.Slider(
                        minimum=0.0,
                        maximum=1.0,
                        step=0.01,
                        value=0.25,
                        label="Confidence Threshold"
                    )
        # --- íƒ­ 2: OCR ---
        with gr.TabItem("2. OCR", elem_id="tab_ocr"):
            ocr_button = gr.Button("Run OCR on Detected Boxes", variant="primary")

            with gr.Row():
                with gr.Column(scale=1):
                    ocr_input_image = gr.Image(label="Original Image with Boxes", 
                                               interactive=False,
                                               scale=1)
                        
                with gr.Column(scale=1):
                    ocr_output_df = gr.Dataframe(
                        label="Extracted Text Table",
                        headers=["BOX ID", "COORDINATES", "DETECTED TEXT"],
                        col_count=(3, "fixed"),
                        row_count="dynamic",
                        value=pd.DataFrame(columns=["BOX ID", "COORDINATES", "DETECTED TEXT"]),
                        datatype=["str", "str", "str"],
                        interactive=True,
                    )
                    
        #                 go_to_translation_button = gr.Button("Go to Translation â†’", variant="secondary", elem_id="btn_translate")
                    
        # # --- íƒ­ 3: Translate ---
        # with gr.TabItem("3. Translate", elem_id="tab_translate"):
        #     with gr.Row():
        #         with gr.Column(scale=1):
        #             gr.Markdown("### Image Preview (with Boxes)")
        #             # â‡ï¸ í…ìŠ¤íŠ¸ ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° (ë²ˆì—­ìš©)
        #             translation_image_preview = gr.Image(
        #                 label="Image Preview",
        #                 interactive=False
        #             )
        #             api_selector = gr.Radio(
        #                 ["Gemini API (Google)", "ChatGPT API (OpenAI)"],
        #                 value="Gemini API (Google)",
        #                 label="Select Translation API"
        #             )
        #             run_translation_button = gr.Button("Run Translation", variant="primary")
                    
        #         with gr.Column(scale=1):
        #             gr.Markdown("### Translation Results")
        #             translation_output_df = gr.Dataframe(
        #                 headers=["ORIGINAL TEXT", "TRANSLATED TEXT"],
        #                 col_count=(2, "fixed"),
        #                 row_count="dynamic",
        #                 value=pd.DataFrame(columns=["ORIGINAL TEXT", "TRANSLATED TEXT"]),
        #                 datatype=["str", "str"],
        #                 interactive=True,
        #             )
                    
        #             go_to_inpaint_button = gr.Button("Go to Inpainting â†’", variant="secondary", elem_id="btn_inpaint")
        
        # # --- íƒ­ 4: Inpainting ---
        # with gr.TabItem("4. Inpainting", elem_id="tab_inpaint"):
        #     gr.Markdown("## ğŸ–Œï¸ Auto Inpainting: Remove Original Text")
        #     with gr.Row():
        #         # --- ì»¬ëŸ¼ 1: ì„¤ì • ë° ì…ë ¥ ì´ë¯¸ì§€ (ì¢Œì¸¡) ---
        #         with gr.Column(scale=1):
        #             gr.Markdown("### Source Image & Settings")
                    
        #             # â‡ï¸ ì¸í˜ì¸íŒ…ì— ì‚¬ìš©í•  ì›ë³¸ ì´ë¯¸ì§€ (ì—…ë¡œë“œëœ ì´ë¯¸ì§€)
        #             inpainting_input_image = gr.Image(
        #                 label="Inpainting Source Image (Uploaded Original)",
        #                 interactive=False,
        #                 height=400 
        #             )
                    
        #             inpainting_model_dropdown = gr.Dropdown(
        #                 ["Lama (Default)", "Other Model (Future)"], 
        #                 value="Lama (Default)",
        #                 label="Select Inpainting Model"
        #             )

        #             # â‡ï¸ [ì¶”ê°€] Dilation ìŠ¬ë¼ì´ë”
        #             dilation_slider = gr.Slider(
        #                 minimum=0,
        #                 maximum=20,
        #                 step=1,
        #                 value=5, 
        #                 label="Mask Dilation (Pixel Size for Expansion)"
        #             )
                    
        #             run_inpainting_button = gr.Button("Run Inpainting", variant="primary")
                
        #         # --- ì»¬ëŸ¼ 2: ìë™ ë§ˆìŠ¤í¬ í‘œì‹œ (ì¤‘ì•™) ---
        #         with gr.Column(scale=2): 
        #             gr.Markdown("### Auto-Mask Preview")
                    
        #             # â‡ï¸ ìë™ ë§ˆìŠ¤í¬ ë¯¸ë¦¬ë³´ê¸° (Grayscale)
        #             inpainting_editor = gr.Image(
        #                 label="Auto-Generated Mask (White areas will be erased)",
        #                 type="numpy",
        #                 image_mode="L", # Grayscaleë¡œ í‘œì‹œ
        #                 height=600 
        #             )

        #         # --- ì»¬ëŸ¼ 3: ê²°ê³¼ ì´ë¯¸ì§€ (ìš°ì¸¡) ---
        #         with gr.Column(scale=1):
        #             gr.Markdown("### Inpainting Result")
                    
        #             inpainting_output_image = gr.Image(
        #                 label="Cleaned Image",
        #                 interactive=False,
        #                 height=600
        #             )
                    
        #             inpainting_status_output = gr.Textbox(
        #                 label="Status",
        #                 value="Ready.",
        #                 interactive=False
        #             )

        #             # â‡ï¸ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì´ë™í•˜ëŠ” ë²„íŠ¼ ì¶”ê°€
        #             go_to_compositing_button = gr.Button("Go to Compositing â†’", variant="secondary", elem_id="btn_compositing")

        # # --- [ìƒˆ íƒ­] íƒ­ 5: Final Compositing ---
        # with gr.TabItem("5. Final Compositing", elem_id="tab_compositing"):
            # gr.Markdown("## âœ¨ Final Output: Composited Image")
            # with gr.Row():
            #     with gr.Column(scale=1):
            #         gr.Markdown("### Compositing Input")
            #         compositing_preview_image = gr.Image(
            #             label="Cleaned Image from Step 4",
            #             interactive=False,
            #             height=400
            #         )
            #         compositing_run_button = gr.Button("Run Final Compositing", variant="primary")
                    
            #     with gr.Column(scale=2):
            #         gr.Markdown("### Final Result")
            #         final_composited_image = gr.Image(
            #             label="Translated Image",
            #             interactive=False,
            #             height=600
            #         )
            #         final_compositing_status = gr.Textbox(
            #             label="Status",
            #             value="Ready.",
            #             interactive=False
            #         )
    
    
    # â‡ï¸ ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
    # 1. 'Detect Text' ë²„íŠ¼ í´ë¦­ ì‹œ
    detect_button.click(
        fn=run_detection,
        inputs=[img_input, model_dropdown, iou_slider, conf_slider, st],
        outputs=[detect_output, ocr_input_image, st]
    )

    # 2. 'Run OCR' ë²„íŠ¼ í´ë¦­ ì‹œ
    ocr_button.click(
        fn=run_ocr,
        inputs=[st], 
        outputs=[ocr_output_df, st]
    )

demo.launch(share=False)